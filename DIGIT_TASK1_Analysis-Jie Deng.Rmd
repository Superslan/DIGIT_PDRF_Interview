---
title: "Phase Adjustment Task: App data analysis"
author: "David Plans"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    fig_caption: yes
  pdf_document: default
---

```{r setup, include=FALSE}
library(tidyverse)
library(jsonlite)
library(RHRV)
library(rstatix)
library(broom)
library(ggpubr)
library(arsenal)
library(ClusterR)
library(mclust)
library(AdaptGauss)
```

<style>
p.caption {
  font-style: italic;
}
</style>

``` {r include=FALSE}
## This project is already set up as a markdown document. For the DIGIT interview, you just need to complete tasks where the comment above says DIGIT-TODO, and run the code/generate the report. Then, create a new branch in the repository, with Firstname_Lastname as the branch name.

# The data.json contains data from a Phase Adjust Task app that measures interoception ability in smartphone users: 
# 
# https://www.sciencedirect.com/science/article/pii/S0301051121001642
# 
# You will be asked to create basic summary statistics out of the data, and to ascertain whether participants just answered randomly, or genuinely, by comparing the actual data to a random distribution.

```

```{r include=FALSE}
## set seed for reproducibilty
set.seed(1234)
## read app data data from prolific JSON
## set up your local path here to point to where the data.json file is in the same directory as DIGIT_PDRF_Analysis.Rmd
data <- rjson::fromJSON(file = "~/Downloads/DIGIT_PDRF_Interview-main/data.json")
```

``` {r, include=F}

# DIGIT: just run this chunk as it's needed below.

### Set Up Formulas.

#Similarity formula - PLV

calc_similarity <- function(delays, periods) {
  angles = delays / periods * 2 * pi
  

  delays_complex <- complex(modulus=periods/(2*pi), argument=angles)
  

  delays_complex_hat <- sapply(delays_complex, 
                            function(a) complex(modulus = 1.0, argument = Arg(a)*Mod(a)*2*pi))
  Similarity <- 1/length(delays_complex_hat)*Mod(sum(delays_complex_hat))
  Similarity
}

calc_similarity_angles <- function(angles) {
  delays_complex_hat <- complex(modulus = 1.0, argument = angles)
  plot(delays_complex_hat)
  Similarity <- 1/length(delays_complex_hat)*Mod(sum(delays_complex_hat))
  Similarity
}

# Find a way to summarise the delays - averaging them doesn't work, we first need to map them as angles. This is what this function is doing: it's finding the arguments of the delays to calculate the mean delay per subject.

becca_argomenti <- function(delays, periods) {
  angles = delays / periods * 2 * pi
  delays_complex <- complex(modulus=periods/(2*pi), argument=angles)
  delays_complex_hat <- sapply(delays_complex, 
                               function(a) complex(modulus = 1.0, argument = Arg(a)*Mod(a)*2*pi))
  Arg(delays_complex_hat)
}

calc_similarity_complex <- function(delays, periods) {
  
  angles = delays / periods * 2 * pi
  

  delays_complex <- complex(modulus=periods/(2*pi), argument=angles)
  

  delays_complex_hat <- sapply(delays_complex, 
                            function(a) complex(modulus = 1.0, argument = Arg(a)*Mod(a)*2*pi))
  mod <- 1/length(delays_complex_hat)*Mod(sum(delays_complex_hat))
  arg <- Arg(sum(delays_complex_hat))
  complex(argument = arg, modulus = mod)
}

#Function that takes the mode out of a variable
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

#Returns random elements from the uniform distribution (between -pi and +pi)
random_x <- runif(5000, -pi, pi)

```


```{r include=FALSE, warning=FALSE}

# DIGIT: just run this chunk as it's needed below.
# 
# 
n_needed_trials<-16
### Create dataframe of summary variables for each individual
# To debug define user_index as a number and run line by line e.g user_index=80
similarities_users_df <- purrr::map_dfr(1:length(data), function(user_index) {
  null_row = list(similarity=NA, 
               confidence=NA,
               bodyPos=NA)
  user_data <- data[[user_index]][[1]]
  
      if (length(user_data$syncroTraining) >= (n_needed_trials+2)) {
        delays <- purrr::map_dbl(user_data$syncroTraining[-c(1,2)], function(trial_data) {
          if (length(trial_data$currentDelays) > 0) {
            trial_data$currentDelays[length(trial_data$currentDelays)]
          } else {
            NA
          }
        })
        
        periods <- purrr::map_dbl(user_data$syncroTraining[-c(1,2)], function(trial_data) {
          if (length(trial_data$averagePeriods) > 0) {
            trial_data$averagePeriods[length(trial_data$averagePeriods)]
          } else {
            NA
          }
        })
        bodyPos <- purrr::map_dbl(user_data$syncroTraining[-c(1,2)], function(trial_data) {
          if (length(trial_data$averagePeriods) > 0) {
            trial_data$bodyPos
          } else {
            NA
          }
        })
        confidence <- purrr::map_dbl(user_data$syncroTraining[-c(1,2)], function(trial_data) {
          if (length(trial_data$averagePeriods) > 0) {
            trial_data$confidence
          } else {
            NA
          }
        })
        HR_trials <- purrr::map_dbl(user_data$syncroTraining[-c(1,2)], function(trial_data) {
          if (length(trial_data$recordedHR) > 0) {
            mean(trial_data$recordedHR, na.rm = T)
          } else {
            NA
          }
        })
        
        time_trials <- purrr::map_dbl(user_data$syncroTraining[-c(1,2)], function(trial_data) {
          if (length(trial_data$instantPeriods) > 0) {
            sum(trial_data$instantPeriods)
          } else {
            NA
          }
        })
        
        engagement_trials <- purrr::map_dbl(user_data$syncroTraining[-c(1,2)], function(trial_data) {
          if (length(trial_data$currentDelays) > 0) {
            length(unique(trial_data$currentDelays))
          } else {
            NA
          }
        })
        # are there at least 4 instantPeriods in each trial
        trial_goodeffort <- purrr::map_dbl(user_data$syncroTraining[-c(1,2)], function(trial_data) {
          if (length(trial_data$instantPeriods) > 4) {
            T
          } else {
            F
          }
        })
        
        # #HRV analysis to control for individual diff
        ibi <- 60/user_data$baselines[[length(user_data$baselines)]]$instantBpms
        hrv_baseline <- CreateHRVData(Verbose = FALSE)
        hrv_baseline <- LoadBeatVector(hrv_baseline, cumsum(ibi))
        hrv_baseline <- BuildNIHR(hrv_baseline)
        hrv_baseline <- FilterNIHR(hrv_baseline)
        hrv_baseline<- CreateTimeAnalysis(hrv_baseline)
        hrv_sdnn <- hrv_baseline$TimeAnalysis[[1]]$SDNN
        hrv_rmssd <- hrv_baseline$TimeAnalysis[[1]]$rMSSD
        hrv_pnn50 <- hrv_baseline$TimeAnalysis[[1]]$pNN50
        taskdate<-user_data$baselines[[length(user_data$baselines)]]$date
        # browser()
        #delays<-delays[!is.na(delays)]
        #periods<-periods[!is.na(periods)]
        valid_trials = (!is.na(periods)) & (!is.na(delays)) & trial_goodeffort
        periods = periods[valid_trials]
        delays = delays[valid_trials]
        
        n_needed_trials = 16

        angles <- becca_argomenti(delays, periods)
        bodyPos<-bodyPos[!is.na(bodyPos)]
        bodyPos<-bodyPos[bodyPos != -1]
        confidence<-confidence[!is.na(confidence)]
        confidence<-confidence[confidence != -1]
        
        if (length(delays) == length(periods) && length(periods) >= n_needed_trials) {
          ## take first 1:n_needed_trials
          my_selection = seq(1:n_needed_trials)
          periods = periods[my_selection]
          delays = delays[my_selection]
          time_trials = time_trials[my_selection]
          engagement_trials = engagement_trials[my_selection]
          trial_goodeffort = trial_goodeffort[my_selection]
          

          list(similarity = calc_similarity(delays, periods),
               id =  user_data$participantID,
               confidence_median =median(confidence),
               confidence_mean = mean(confidence),
               confidence_sd = sd(confidence),
               # removed angles as not used
               #angles_min = min(angles),
               #angles_max = max(angles),
               # below not subset as delays/periods above and not used so removed
               #bodyPos= getmode(bodyPos),
               count_bodyPos = length(unique(bodyPos)),
               mean_delays = mean(Arg(calc_similarity_complex(delays,periods))/(2*pi)),
               mean_angle = Arg(calc_similarity_complex(delays, periods)),
               delays_ms = Arg(calc_similarity_complex(delays,periods))/(2*pi),
               sd_delays = sd(Arg(calc_similarity_complex(delays,periods)))/(2*pi),
               mean_HR = mean(HR_trials, na.rm = TRUE),
               hrv_sdnn = hrv_sdnn,
               hrv_rmssd = hrv_rmssd,
               hrv_pnn50 = hrv_pnn50,
               original_index = user_index,
               mean_time_trials = mean(time_trials),
               sd_time_trials = sd(time_trials),
               mean_engagement_trials = mean(engagement_trials),
               sd_engagement_trials = sd(engagement_trials),
               tot_time = sum(time_trials),
               count_validtrials = sum(valid_trials),
               count_usedTrials = length(my_selection),
               taskdate= taskdate
               )
        } else {
          null_row
        }
      } else {
        null_row
      }

  }
 )

Sims<- similarities_users_df %>% filter( !is.na(similarity))


Nparticipants<-nrow(Sims)



```




```{r include=FALSE}

# DIGIT TODO : Create Summary Statistics
# `r Nparticipants` individuals successfully provided data through the app and prolific system. Similarity scores were calculated using the first `r n_needed_trials` trials for each individual. Please create summary statistics for similarity scores as well as confidence_mean, mean_HR, hrv_sdnn, hrv_rmssd, hrv_pnn50, mean_time_trials, mean_engagement_trials using the Sims data object created by the code above, and which should now be available in your Environment.

```
summary(Sims)
#or
library(psych)
describe(Sims)
describe(Sims$similarity)
describe(Sims$confidence_mean)
describe(Sims$mean_HR)
describe(Sims$hrv_sdnn)
describe(Sims$hrv_rmssd)
describe(Sims$hrv_pnn50)
describe(Sims$mean_time_trials)
describe(Sims$mean_engagement_trials)
```{r echo=FALSE, results='asis'}
# DIGIT TODO: create a nicely formatted table of the summary stats you produced above


```
tb_one <- tableby(~similarity +confidence_mean + mean_HR+ hrv_sdnn + hrv_rmssd+ hrv_pnn50+
                    + mean_time_trials+ mean_engagement_trials, data=Sims)
summary(tb_one)

```{r echo=F}
## DIGIT TODO: Show wether participant responses were better than random. To compare participants responses to a randomly generated distribution, create a random distribution (using something like Phase Locking Value).



```
#adjusted from original paper
max_iter <- 500

similarities_random30 <- purrr::map_dbl(1:max_iter, function(i) {
  n <- 30
  periods <- runif(n, 0.5, 1.5)
  delays <- purrr::map_dbl(periods, function(p) runif(1, 0, p))
  calc_similarity(delays, periods)
})



```{r include=F}
# plot the distributions together (random and real)
# Were participant responses non-random?


```
#adjusted from original paper
plot(density(similarities_random30), type="l", col=2, 
     main = "",
     xlab = "Similarity",
     ylim = c(0, 4))
points(density(Sims$similarity, na.rm = T), type="l", col=1)
legend("topright", legend = c("PDF simulated answers", "PDF real answers"), lty=c(1,1), col=c("red", "black"))

model1 <- t.test(Sims$similarity, similarities_random30)

#p<.01,yes, participant responses non-random.

